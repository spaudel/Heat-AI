{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNBX+VRZBtC6Ry2vjZvybbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaudel/Heat-AI/blob/main/HeatAI_temperature_anomaly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThwGVO60Nyf"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Pandas for reading and processing csvs\n",
        "import pandas as pd\n",
        "from sklearn.svm import OneClassSVM\n",
        "## Json decode\n",
        "import json\n",
        "\n",
        "## Use requests to get api data\n",
        "import requests\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GITHUB_PRIVATE_KEY=\"\"\"\n",
        "# -----BEGIN OPENSSH PRIVATE KEY-----\n",
        "# b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "# QyNTUxOQAAACD+G105r/n9fltpyWPUUS4aaJW9guwLk8QWFstbnCyLiAAAAKi4BbELuAWx\n",
        "# CwAAAAtzc2gtZWQyNTUxOQAAACD+G105r/n9fltpyWPUUS4aaJW9guwLk8QWFstbnCyLiA\n",
        "# AAAECOpbTSVz8qO6gNM8Q+Dg5N1pMaFJ6eB3tFn5ObiHGfWP4bXTmv+f1+W2nJY9RRLhpo\n",
        "# lb2C7AuTxBYWy1ucLIuIAAAAIXNocmV5YXNoYUBTaHJleWFzaGFLb0NvbXAtMi5sb2NhbA\n",
        "# ECAwQ=\n",
        "# -----END OPENSSH PRIVATE KEY-----\n",
        "# \"\"\"\n",
        "\n",
        "# # Create the directory if it doesn't exist.\n",
        "# ! mkdir -p /root/.ssh\n",
        "# # Write the key\n",
        "# with open(\"/root/.ssh/id_ed25519\", \"w\") as f:\n",
        "#   f.write(GITHUB_PRIVATE_KEY)\n",
        "# # Add github.com to our known hosts\n",
        "# ! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "# # Restrict the key permissions, or else SSH will complain.\n",
        "# ! chmod go-rwx /root/.ssh/id_ed25519\n",
        "\n",
        "# ! git clone git@github.com:spaudel/Heat-AI.git\n",
        "# %cd /content/Heat-AI\n",
        "!pip list | grep scikit-learn"
      ],
      "metadata": {
        "id": "CTSRR027HBwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "district_id = '64' #surkhet. TODO: create a function for this\n",
        "from_date_time = '2024-09-25'\n",
        "to_date_time = '2024-10-05'\n",
        "\n",
        "# the below url gets hourly forecast for the district for the given start and end date\n",
        "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=64&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
        "surkhet_forecast_output = requests.get(request_url)\n",
        "\n",
        "surkhet_forecast_dict = surkhet_forecast_output.json()\n",
        "\n",
        "district_id = '66' #banke. TODO: create a function for this\n",
        "\n",
        "\n",
        "# the below url gets hourly forecast for the district for the given start and end date\n",
        "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=66&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
        "banke_forecast_output = requests.get(request_url)\n",
        "\n",
        "banke_forecast_dict = banke_forecast_output.json()\n",
        "\n",
        "district_id = '55' #salyan. TODO: create a function for this\n",
        "\n",
        "\n",
        "# the below url gets hourly forecast for the district for the given start and end date\n",
        "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=55&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
        "salyan_forecast_output = requests.get(request_url)\n",
        "\n",
        "salyan_forecast_dict = salyan_forecast_output.json()\n",
        "\n",
        "\n",
        "district_id = '65' #bardiya. TODO: create a function for this\n",
        "\n",
        "\n",
        "# the below url gets hourly forecast for the district for the given start and end date\n",
        "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=65&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
        "bardiya_forecast_output = requests.get(request_url)\n",
        "\n",
        "bardiya_forecast_dict = bardiya_forecast_output.json()"
      ],
      "metadata": {
        "id": "Rrb9rpaMa2iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vhtc7wM1G_tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the dictionary to create an array\n",
        "def get_forecast_array(forecast_dict):\n",
        "  array_dict = {}\n",
        "  for key in forecast_dict[0].keys():\n",
        "    for x in range(len(forecast_dict)):\n",
        "      if key in array_dict:\n",
        "        array_dict[key].append(forecast_dict[x][key])\n",
        "      else:\n",
        "        array_dict[key] = [forecast_dict[x][key]]\n",
        "  return array_dict;\n",
        "\n"
      ],
      "metadata": {
        "id": "VuMiFH9FbxkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "surkhet_array_dict = get_forecast_array(surkhet_forecast_dict)\n",
        "banke_array_dict = get_forecast_array(banke_forecast_dict)\n",
        "salyan_array_dict = get_forecast_array(salyan_forecast_dict)\n",
        "bardiya_array_dict = get_forecast_array(bardiya_forecast_dict)"
      ],
      "metadata": {
        "id": "Pyu75Vxdntq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(surkhet_array_dict['air_temperature'])\n",
        "plt.plot(banke_array_dict['air_temperature'])\n",
        "plt.plot(salyan_array_dict['air_temperature'])\n",
        "plt.plot(bardiya_array_dict['air_temperature'])\n",
        "plt.legend(['surkhet','banke','salyan', 'bardiya'])"
      ],
      "metadata": {
        "id": "3EgGDIVycBNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(surkhet_array_dict['relative_humidity'])\n",
        "plt.plot(banke_array_dict['relative_humidity'])\n",
        "plt.plot(salyan_array_dict['relative_humidity'])\n",
        "plt.plot(bardiya_array_dict['relative_humidity'])\n",
        "plt.legend(['surkhet','banke','salyan', 'bardiya'])"
      ],
      "metadata": {
        "id": "cacTitBHcfZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(surkhet_forecast_dict[0].keys())\n",
        "print(len(surkhet_array_dict['air_temperature']))"
      ],
      "metadata": {
        "id": "fkqCYG2Tm49g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(surkhet_array_dict['calculated_heat_index'])\n",
        "plt.plot(banke_array_dict['calculated_heat_index'])\n",
        "plt.plot(salyan_array_dict['calculated_heat_index'])\n",
        "plt.plot(bardiya_array_dict['calculated_heat_index'])\n",
        "plt.legend(['surkhet','banke','salyan', 'bardiya'])"
      ],
      "metadata": {
        "id": "-Blus1WmpBpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_month(x):\n",
        "     return pd.to_numeric(pd.Series(x.split('-')))"
      ],
      "metadata": {
        "id": "kSQmME1kdTME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load csv of historical data\n",
        "\n",
        "histdata_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/Badhaiyatal_open-meteo-28.15N81.45E146m.csv\"\n",
        "hist_df = pd.read_csv(histdata_url)\n",
        "print(hist_df)\n",
        "# Add column of dates\n",
        "histdata_dates = hist_df['time'].apply(lambda x: extract_month(x))\n",
        "histdata_dates.columns = ['yy','mm','dd']\n",
        "#print(histdata_dates['yy'])\n",
        "\n",
        "# Prepare training data with summer temperatures for 25 years\n",
        "hist_df_25yrs = hist_df.loc[histdata_dates['yy'].isin(range(1993,2018))]\n",
        "filtered_indices = histdata_dates['yy'].isin(range(1993,2018)) & histdata_dates['mm'].isin(range(4,10))\n",
        "summer_df_25yrs = hist_df_25yrs.loc[filtered_indices] #summer months: April to September.\n",
        "filtered_yrs = histdata_dates['yy'].loc[filtered_indices]\n",
        "\n",
        "#Plot summer temperatures for training data\n",
        "plt.plot(filtered_yrs,summer_df_25yrs['temperature_2m_max (°C)'], '*')\n",
        "plt.plot(filtered_yrs,summer_df_25yrs['temperature_2m_min (°C)'], '+')\n",
        "plt.plot(filtered_yrs,summer_df_25yrs['temperature_2m_mean (°C)'], 'o')\n",
        "plt.legend(['max','min','mean'])"
      ],
      "metadata": {
        "id": "8NyazPETpLhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "\n",
        "# from sklearn.covariance import EllipticEnvelope\n",
        "# from sklearn.ensemble import IsolationForest\n",
        "# from sklearn.kernel_approximation import Nystroem\n",
        "# from sklearn.linear_model import SGDOneClassSVM\n",
        "# from sklearn.neighbors import LocalOutlierFactor\n",
        "# from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "xxjlKIIY1O7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate moving average as training data\n",
        "# Prepare training data with summer temperatures for 25 years\n",
        "hist_df_20yrs = hist_df.loc[histdata_dates['yy'].isin(range(1993,2018))]\n",
        "filtered_indices = histdata_dates['yy'].isin(range(1993,2016)) & histdata_dates['mm'].isin(range(4,10))\n",
        "summer_df_25yrs = hist_df_25yrs.loc[filtered_indices] #summer months: April to September.\n",
        "filtered_yrs = histdata_dates['yy'].loc[filtered_indices]\n",
        "\n",
        "#Calculate series of moving averages for entire dataset\n",
        "maxtemp_sma = hist_df['temperature_2m_max (°C)']#.rolling(window=1).mean()\n",
        "mintemp_sma = hist_df['temperature_2m_min (°C)']#.rolling(window=1).mean()\n",
        "meantemp_sma = hist_df['temperature_2m_mean (°C)']#.rolling(window=1).mean()\n",
        "apptempmax_sma = hist_df['apparent_temperature_max (°C)']#.rolling(window=1).mean()\n",
        "apptempmin_sma = hist_df['apparent_temperature_min (°C)']#.rolling(window=1).mean()\n",
        "apptempmean_sma = hist_df['apparent_temperature_mean (°C)']#.rolling(window=1).mean()\n",
        "prec_sma = hist_df['precipitation_sum (mm)']#.rolling(window=3).mean()\n",
        "\n",
        "# Extract summer temperature\n",
        "summer_df_25yrs = hist_df_25yrs.loc[filtered_indices]\n",
        "X_train = np.column_stack([maxtemp_sma[filtered_indices],\n",
        "              mintemp_sma[filtered_indices],\n",
        "              meantemp_sma[filtered_indices],\n",
        "              apptempmax_sma[filtered_indices],\n",
        "              apptempmin_sma[filtered_indices],\n",
        "              apptempmean_sma[filtered_indices],\n",
        "              prec_sma[filtered_indices]\n",
        "              ])\n",
        "print(X_train.shape)\n",
        "\n",
        "test_index_summer = histdata_dates['yy'].isin(range(2019,2023)) & histdata_dates['mm'].isin(range(4,10))\n",
        "test_index_winter = histdata_dates['yy'].isin(range(2019,2023)) & ~(histdata_dates['mm'].isin(range(3,11)))\n",
        "X_test_summer = np.column_stack([maxtemp_sma[test_index_summer],\n",
        "              mintemp_sma[test_index_summer],\n",
        "              meantemp_sma[test_index_summer],\n",
        "              apptempmax_sma[test_index_summer],\n",
        "              apptempmin_sma[test_index_summer],\n",
        "              apptempmean_sma[test_index_summer],\n",
        "              prec_sma[test_index_summer]\n",
        "              ])\n",
        "X_test_winter = np.column_stack([maxtemp_sma[test_index_winter],\n",
        "              mintemp_sma[test_index_winter],\n",
        "              meantemp_sma[test_index_winter],\n",
        "              apptempmax_sma[test_index_winter],\n",
        "              apptempmin_sma[test_index_winter],\n",
        "              apptempmean_sma[test_index_winter],\n",
        "              prec_sma[test_index_winter]\n",
        "              ])\n",
        "\n",
        "print(X_train.shape, X_test_summer.shape, X_test_winter.shape)\n",
        "\n",
        "# Train svm\n",
        "# OCSVM hyperparameters\n",
        "nu = 0.09\n",
        "gamma = 2.0\n",
        "clf = OneClassSVM(gamma='scale', kernel=\"rbf\", nu=nu)\n",
        "clf.fit(X_train)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test_summer)\n",
        "y_pred_outliers = clf.predict(X_test_winter)\n",
        "n_error_train = y_pred_train[y_pred_train == -1].size\n",
        "n_error_test = y_pred_test[y_pred_test == -1].size\n",
        "n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
        "print(\"ERROR RATES:\")\n",
        "print(n_error_train/len(y_pred_train), n_error_test/len(y_pred_test), n_error_outliers/len(y_pred_outliers))\n",
        "\n",
        "# Visualization of predicted outlier temperature\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.plot(mintemp_sma[test_index_winter], '*', label='Original Data')\n",
        "# plt.plot(maxtemp_sma[test_index_winter], 'o', label='7-Day SMA')\n"
      ],
      "metadata": {
        "id": "oa7G-Sv3QB22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn this into function\n",
        "\n",
        "def create_train_test_data(hist_df,y_begin=1993, y_end=2013, m_begin=4,m_end=9):\n",
        "\n",
        "  # get yy,mm,dd for filtering\n",
        "  histdata_dates = hist_df['time'].apply(lambda x: extract_month(x))\n",
        "  histdata_dates.columns = ['yy','mm','dd']\n",
        "  train_summer_filter = histdata_dates['yy'].isin(range(y_begin, y_end)) & histdata_dates['mm'].isin(range(m_begin, m_end))\n",
        "  test_summer_filter = histdata_dates['yy'].isin(range(y_end, 2023)) & histdata_dates['mm'].isin(range(m_begin, m_end))\n",
        "  train_winter_filter = histdata_dates['yy'].isin(range(y_begin, y_end)) & \\\n",
        "                          (histdata_dates['mm'].isin(range(1, m_begin)) | histdata_dates['mm'].isin(range(m_end, 12)))\n",
        "  test_winter_filter = histdata_dates['yy'].isin(range(y_end, 2023)) & \\\n",
        "                          (histdata_dates['mm'].isin(range(1, m_begin)) | histdata_dates['mm'].isin(range(m_end, 12)))\n",
        "\n",
        "  # Extract feature\n",
        "  maxtemp_sma = hist_df['temperature_2m_max (°C)']\n",
        "  mintemp_sma = hist_df['temperature_2m_min (°C)']\n",
        "  meantemp_sma = hist_df['temperature_2m_mean (°C)']\n",
        "  apptempmax_sma = hist_df['apparent_temperature_max (°C)']#.rolling(window=1).mean()\n",
        "  apptempmin_sma = hist_df['apparent_temperature_min (°C)']#.rolling(window=1).mean()\n",
        "  apptempmean_sma = hist_df['apparent_temperature_mean (°C)']#.rolling(window=1).mean()\n",
        "  prec_sma = hist_df['precipitation_sum (mm)']#.rolling(window=3).mean()\n",
        "\n",
        "  # Form train and test matrices\n",
        "  X_train_summer = np.column_stack([maxtemp_sma[train_summer_filter],\n",
        "                                    mintemp_sma[train_summer_filter],\n",
        "                                    meantemp_sma[train_summer_filter],\n",
        "                                    apptempmax_sma[train_summer_filter],\n",
        "                                    apptempmin_sma[train_summer_filter],\n",
        "                                    apptempmean_sma[train_summer_filter],\n",
        "                                    prec_sma[train_summer_filter]\n",
        "                                  ])\n",
        "\n",
        "  X_train_winter = np.column_stack([maxtemp_sma[train_winter_filter],\n",
        "                                    mintemp_sma[train_winter_filter],\n",
        "                                    meantemp_sma[train_winter_filter],\n",
        "                                    apptempmax_sma[train_winter_filter],\n",
        "                                    apptempmin_sma[train_winter_filter],\n",
        "                                    apptempmean_sma[train_winter_filter],\n",
        "                                    prec_sma[train_winter_filter]\n",
        "                                  ])\n",
        "\n",
        "  X_test_summer = np.column_stack([maxtemp_sma[test_summer_filter],\n",
        "                                    mintemp_sma[test_summer_filter],\n",
        "                                    meantemp_sma[test_summer_filter],\n",
        "                                    apptempmax_sma[test_summer_filter],\n",
        "                                    apptempmin_sma[test_summer_filter],\n",
        "                                    apptempmean_sma[test_summer_filter],\n",
        "                                    prec_sma[test_summer_filter]\n",
        "                                  ])\n",
        "  X_test_winter = np.column_stack([maxtemp_sma[test_winter_filter],\n",
        "                                    mintemp_sma[test_winter_filter],\n",
        "                                    meantemp_sma[test_winter_filter],\n",
        "                                    apptempmax_sma[test_winter_filter],\n",
        "                                    apptempmin_sma[test_winter_filter],\n",
        "                                    apptempmean_sma[test_winter_filter],\n",
        "                                    prec_sma[test_winter_filter]\n",
        "                                  ])\n",
        "\n",
        "  return X_train_summer, X_train_winter, X_test_summer, X_test_winter\n",
        "\n",
        "\n",
        "def train_svm(X_train):\n",
        "  # OCSVM hyperparameters\n",
        "  nu = 0.09\n",
        "  gamma = 2.0\n",
        "  clf = OneClassSVM(gamma='scale', kernel=\"rbf\", nu=nu)\n",
        "  clf.fit(X_train)\n",
        "\n",
        "  y_pred_train = clf.predict(X_train)\n",
        "  n_error_train = y_pred_train[y_pred_train == -1].size\n",
        "  print(\"Training Error:\", n_error_train/len(y_pred_train) * 100)\n",
        "\n",
        "  return clf\n",
        "\n",
        "\n",
        "def test_svm(clf, X_test, y_actual):\n",
        "  y_pred = clf.predict(X_test)\n",
        "  # Model Accuracy: how often is the classifier correct?\n",
        "  print(\"Accuracy:\",metrics.accuracy_score(y_actual, y_pred))\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LHjqMsPCoKlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on 5 municipalities\n",
        "mun1_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/Badhaiyatal_open-meteo-28.15N81.45E146m.csv\"\n",
        "mun1_df = pd.read_csv(mun1_url)\n",
        "\n",
        "X1_train_summer, X1_train_winter, X1_test_summer, X1_test_winter = create_train_test_data(mun1_df)\n",
        "model1 = train_svm(X1_train_summer)\n",
        "print(\"Testing historical winter\")\n",
        "test_svm(model1, X1_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
        "print (\"Testing Summer post 2019\")\n",
        "test_svm(model1, X1_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
        "print (\"Testing Winter post 2019\")\n",
        "test_svm(model1, X1_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n"
      ],
      "metadata": {
        "id": "ZE4hcPEBHAGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mun_array_dict = get_forecast_array(mun_forecast_dict)\n",
        "plt.plot(mun_array_dict['air_temperature'])"
      ],
      "metadata": {
        "id": "v2YDZegXzx_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function\n"
      ],
      "metadata": {
        "id": "D5wpIfucz-CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYy5LA3W3vf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SnEzmAzn30u1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}