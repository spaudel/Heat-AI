{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/spaudel/Heat-AI/blob/main/HeatAI_temperature_anomaly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lThwGVO60Nyf"
   },
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Pandas for reading and processing csvs\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM\n",
    "## Json decode\n",
    "import json\n",
    "\n",
    "## Use requests to get api data\n",
    "import requests\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTSRR027HBwQ"
   },
   "outputs": [],
   "source": [
    "# GITHUB_PRIVATE_KEY=\"\"\"\n",
    "# -----BEGIN OPENSSH PRIVATE KEY-----\n",
    "# b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
    "# QyNTUxOQAAACD+G105r/n9fltpyWPUUS4aaJW9guwLk8QWFstbnCyLiAAAAKi4BbELuAWx\n",
    "# CwAAAAtzc2gtZWQyNTUxOQAAACD+G105r/n9fltpyWPUUS4aaJW9guwLk8QWFstbnCyLiA\n",
    "# AAAECOpbTSVz8qO6gNM8Q+Dg5N1pMaFJ6eB3tFn5ObiHGfWP4bXTmv+f1+W2nJY9RRLhpo\n",
    "# lb2C7AuTxBYWy1ucLIuIAAAAIXNocmV5YXNoYUBTaHJleWFzaGFLb0NvbXAtMi5sb2NhbA\n",
    "# ECAwQ=\n",
    "# -----END OPENSSH PRIVATE KEY-----\n",
    "# \"\"\"\n",
    "\n",
    "# # Create the directory if it doesn't exist.\n",
    "# ! mkdir -p /root/.ssh\n",
    "# # Write the key\n",
    "# with open(\"/root/.ssh/id_ed25519\", \"w\") as f:\n",
    "#   f.write(GITHUB_PRIVATE_KEY)\n",
    "# # Add github.com to our known hosts\n",
    "# ! ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
    "# # Restrict the key permissions, or else SSH will complain.\n",
    "# ! chmod go-rwx /root/.ssh/id_ed25519\n",
    "\n",
    "# ! git clone git@github.com:spaudel/Heat-AI.git\n",
    "# %cd /content/Heat-AI\n",
    "!pip list | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rrb9rpaMa2iT"
   },
   "outputs": [],
   "source": [
    "\n",
    "district_id = '64' #surkhet. TODO: create a function for this\n",
    "from_date_time = '2024-09-25'\n",
    "to_date_time = '2024-10-05'\n",
    "\n",
    "# the below url gets hourly forecast for the district for the given start and end date\n",
    "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=64&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
    "surkhet_forecast_output = requests.get(request_url)\n",
    "\n",
    "surkhet_forecast_dict = surkhet_forecast_output.json()\n",
    "\n",
    "district_id = '66' #banke. TODO: create a function for this\n",
    "\n",
    "\n",
    "# the below url gets hourly forecast for the district for the given start and end date\n",
    "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=66&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
    "banke_forecast_output = requests.get(request_url)\n",
    "\n",
    "banke_forecast_dict = banke_forecast_output.json()\n",
    "\n",
    "district_id = '55' #salyan. TODO: create a function for this\n",
    "\n",
    "\n",
    "# the below url gets hourly forecast for the district for the given start and end date\n",
    "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=55&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
    "salyan_forecast_output = requests.get(request_url)\n",
    "\n",
    "salyan_forecast_dict = salyan_forecast_output.json()\n",
    "\n",
    "\n",
    "district_id = '65' #bardiya. TODO: create a function for this\n",
    "\n",
    "\n",
    "# the below url gets hourly forecast for the district for the given start and end date\n",
    "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/district-location-forecasts/?district=65&fromdatetime=2024-09-25&todatetime=2024-10-05'\n",
    "bardiya_forecast_output = requests.get(request_url)\n",
    "\n",
    "bardiya_forecast_dict = bardiya_forecast_output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vhtc7wM1G_tE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuMiFH9FbxkS"
   },
   "outputs": [],
   "source": [
    "# Decode the dictionary to create an array\n",
    "def get_forecast_array(forecast_dict):\n",
    "  array_dict = {}\n",
    "  for key in forecast_dict[0].keys():\n",
    "    for x in range(len(forecast_dict)):\n",
    "      if key in array_dict:\n",
    "        array_dict[key].append(forecast_dict[x][key])\n",
    "      else:\n",
    "        array_dict[key] = [forecast_dict[x][key]]\n",
    "  return array_dict;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pyu75Vxdntq9"
   },
   "outputs": [],
   "source": [
    "surkhet_array_dict = get_forecast_array(surkhet_forecast_dict)\n",
    "banke_array_dict = get_forecast_array(banke_forecast_dict)\n",
    "salyan_array_dict = get_forecast_array(salyan_forecast_dict)\n",
    "bardiya_array_dict = get_forecast_array(bardiya_forecast_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EgGDIVycBNo"
   },
   "outputs": [],
   "source": [
    "plt.plot(surkhet_array_dict['air_temperature'])\n",
    "plt.plot(banke_array_dict['air_temperature'])\n",
    "plt.plot(salyan_array_dict['air_temperature'])\n",
    "plt.plot(bardiya_array_dict['air_temperature'])\n",
    "plt.legend(['surkhet','banke','salyan', 'bardiya'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cacTitBHcfZW"
   },
   "outputs": [],
   "source": [
    "plt.plot(surkhet_array_dict['relative_humidity'])\n",
    "plt.plot(banke_array_dict['relative_humidity'])\n",
    "plt.plot(salyan_array_dict['relative_humidity'])\n",
    "plt.plot(bardiya_array_dict['relative_humidity'])\n",
    "plt.legend(['surkhet','banke','salyan', 'bardiya'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkqCYG2Tm49g"
   },
   "outputs": [],
   "source": [
    "print(surkhet_forecast_dict[0].keys())\n",
    "print(len(surkhet_array_dict['air_temperature']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Blus1WmpBpe"
   },
   "outputs": [],
   "source": [
    "plt.plot(surkhet_array_dict['calculated_heat_index'])\n",
    "plt.plot(banke_array_dict['calculated_heat_index'])\n",
    "plt.plot(salyan_array_dict['calculated_heat_index'])\n",
    "plt.plot(bardiya_array_dict['calculated_heat_index'])\n",
    "plt.legend(['surkhet','banke','salyan', 'bardiya'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSQmME1kdTME"
   },
   "outputs": [],
   "source": [
    "def extract_month(x):\n",
    "     return pd.to_numeric(pd.Series(x.split('-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NyazPETpLhL"
   },
   "outputs": [],
   "source": [
    "# Load csv of historical data\n",
    "\n",
    "# histdata_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/Badhaiyatal_open-meteo-28.15N81.45E146m.csv\"\n",
    "# hist_df = pd.read_csv(histdata_url)\n",
    "# print(hist_df)\n",
    "# # Add column of dates\n",
    "# histdata_dates = hist_df['time'].apply(lambda x: extract_month(x))\n",
    "# histdata_dates.columns = ['yy','mm','dd']\n",
    "# #print(histdata_dates['yy'])\n",
    "\n",
    "# # Prepare training data with summer temperatures for 25 years\n",
    "# hist_df_25yrs = hist_df.loc[histdata_dates['yy'].isin(range(1993,2018))]\n",
    "# filtered_indices = histdata_dates['yy'].isin(range(1993,2018)) & histdata_dates['mm'].isin(range(4,10))\n",
    "# summer_df_25yrs = hist_df_25yrs.loc[filtered_indices] #summer months: April to September.\n",
    "# filtered_yrs = histdata_dates['yy'].loc[filtered_indices]\n",
    "\n",
    "# #Plot summer temperatures for training data\n",
    "# plt.plot(filtered_yrs,summer_df_25yrs['temperature_2m_max (°C)'], '*')\n",
    "# plt.plot(filtered_yrs,summer_df_25yrs['temperature_2m_min (°C)'], '+')\n",
    "# plt.plot(filtered_yrs,summer_df_25yrs['temperature_2m_mean (°C)'], 'o')\n",
    "# plt.legend(['max','min','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxjlKIIY1O7H"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.covariance import EllipticEnvelope\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.kernel_approximation import Nystroem\n",
    "# from sklearn.linear_model import SGDOneClassSVM\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "# from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oa7G-Sv3QB22"
   },
   "outputs": [],
   "source": [
    "# Calculate moving average as training data\n",
    "# Prepare training data with summer temperatures for 25 years\n",
    "# hist_df_20yrs = hist_df.loc[histdata_dates['yy'].isin(range(1993,2018))]\n",
    "# filtered_indices = histdata_dates['yy'].isin(range(1993,2016)) & histdata_dates['mm'].isin(range(4,10))\n",
    "# summer_df_25yrs = hist_df_25yrs.loc[filtered_indices] #summer months: April to September.\n",
    "# filtered_yrs = histdata_dates['yy'].loc[filtered_indices]\n",
    "\n",
    "# #Calculate series of moving averages for entire dataset\n",
    "# maxtemp_sma = hist_df['temperature_2m_max (°C)']#.rolling(window=1).mean()\n",
    "# mintemp_sma = hist_df['temperature_2m_min (°C)']#.rolling(window=1).mean()\n",
    "# meantemp_sma = hist_df['temperature_2m_mean (°C)']#.rolling(window=1).mean()\n",
    "# apptempmax_sma = hist_df['apparent_temperature_max (°C)']#.rolling(window=1).mean()\n",
    "# apptempmin_sma = hist_df['apparent_temperature_min (°C)']#.rolling(window=1).mean()\n",
    "# apptempmean_sma = hist_df['apparent_temperature_mean (°C)']#.rolling(window=1).mean()\n",
    "# prec_sma = hist_df['precipitation_sum (mm)']#.rolling(window=3).mean()\n",
    "\n",
    "# # Extract summer temperature\n",
    "# summer_df_25yrs = hist_df_25yrs.loc[filtered_indices]\n",
    "# X_train = np.column_stack([maxtemp_sma[filtered_indices],\n",
    "#               mintemp_sma[filtered_indices],\n",
    "#               meantemp_sma[filtered_indices],\n",
    "#               apptempmax_sma[filtered_indices],\n",
    "#               apptempmin_sma[filtered_indices],\n",
    "#               apptempmean_sma[filtered_indices],\n",
    "#               prec_sma[filtered_indices]\n",
    "#               ])\n",
    "# print(X_train.shape)\n",
    "\n",
    "# test_index_summer = histdata_dates['yy'].isin(range(2019,2023)) & histdata_dates['mm'].isin(range(4,10))\n",
    "# test_index_winter = histdata_dates['yy'].isin(range(2019,2023)) & ~(histdata_dates['mm'].isin(range(3,11)))\n",
    "# X_test_summer = np.column_stack([maxtemp_sma[test_index_summer],\n",
    "#               mintemp_sma[test_index_summer],\n",
    "#               meantemp_sma[test_index_summer],\n",
    "#               apptempmax_sma[test_index_summer],\n",
    "#               apptempmin_sma[test_index_summer],\n",
    "#               apptempmean_sma[test_index_summer],\n",
    "#               prec_sma[test_index_summer]\n",
    "#               ])\n",
    "# X_test_winter = np.column_stack([maxtemp_sma[test_index_winter],\n",
    "#               mintemp_sma[test_index_winter],\n",
    "#               meantemp_sma[test_index_winter],\n",
    "#               apptempmax_sma[test_index_winter],\n",
    "#               apptempmin_sma[test_index_winter],\n",
    "#               apptempmean_sma[test_index_winter],\n",
    "#               prec_sma[test_index_winter]\n",
    "#               ])\n",
    "\n",
    "# print(X_train.shape, X_test_summer.shape, X_test_winter.shape)\n",
    "\n",
    "# # Train svm\n",
    "# # OCSVM hyperparameters\n",
    "# nu = 0.09\n",
    "# gamma = 2.0\n",
    "# clf = OneClassSVM(gamma='scale', kernel=\"rbf\", nu=nu)\n",
    "# clf.fit(X_train)\n",
    "# y_pred_train = clf.predict(X_train)\n",
    "# y_pred_test = clf.predict(X_test_summer)\n",
    "# y_pred_outliers = clf.predict(X_test_winter)\n",
    "# n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "# n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "# n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "# print(\"ERROR RATES:\")\n",
    "# print(n_error_train/len(y_pred_train), n_error_test/len(y_pred_test), n_error_outliers/len(y_pred_outliers))\n",
    "\n",
    "# Visualization of predicted outlier temperature\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(mintemp_sma[test_index_winter], '*', label='Original Data')\n",
    "# plt.plot(maxtemp_sma[test_index_winter], 'o', label='7-Day SMA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHjqMsPCoKlb"
   },
   "outputs": [],
   "source": [
    "# Turn this into function\n",
    "\n",
    "def create_train_test_data(hist_df,y_begin=1993, y_end=2019, m_begin=4,m_end=9):\n",
    "\n",
    "  # get yy,mm,dd for filtering\n",
    "  histdata_dates = hist_df['time'].apply(lambda x: extract_month(x))\n",
    "  histdata_dates.columns = ['yy','mm','dd']\n",
    "  train_summer_filter = histdata_dates['yy'].isin(range(y_begin, y_end)) #& histdata_dates['mm'].isin(range(m_begin, m_end))\n",
    "  test_summer_filter = histdata_dates['yy'].isin(range(y_end, 2023)) & histdata_dates['mm'].isin(range(m_begin, m_end))\n",
    "  train_winter_filter = histdata_dates['yy'].isin(range(y_begin, y_end)) & \\\n",
    "                          (histdata_dates['mm'].isin(range(1, m_begin)) | histdata_dates['mm'].isin(range(m_end, 12)))\n",
    "  test_winter_filter = histdata_dates['yy'].isin(range(y_end, 2023)) & \\\n",
    "                          (histdata_dates['mm'].isin(range(1, m_begin)) | histdata_dates['mm'].isin(range(m_end, 12)))\n",
    "\n",
    "  # Extract feature\n",
    "  maxtemp = hist_df['temperature_2m_max (°C)']\n",
    "  mintemp = hist_df['temperature_2m_min (°C)']\n",
    "  meantemp = hist_df['temperature_2m_mean (°C)']\n",
    "  apptempmax = hist_df['apparent_temperature_max (°C)']#.rolling(window=1).mean()\n",
    "  apptempmin = hist_df['apparent_temperature_min (°C)']#.rolling(window=1).mean()\n",
    "  apptempmean = hist_df['apparent_temperature_mean (°C)']#.rolling(window=1).mean()\n",
    "  prec = hist_df['precipitation_sum (mm)']#.rolling(window=3).mean()\n",
    "\n",
    "  # Extract moving average for training\n",
    "  maxtemp_sma = hist_df['temperature_2m_max (°C)'].rolling(window=5,min_periods=1).mean()\n",
    "  mintemp_sma = hist_df['temperature_2m_min (°C)'].rolling(window=5,min_periods=1).mean()\n",
    "  meantemp_sma = hist_df['temperature_2m_mean (°C)'].rolling(window=5,min_periods=1).mean()\n",
    "  apptempmax_sma = hist_df['apparent_temperature_max (°C)'].rolling(window=5,min_periods=1).mean()\n",
    "  apptempmin_sma = hist_df['apparent_temperature_min (°C)'].rolling(window=5,min_periods=1).mean()\n",
    "  apptempmean_sma = hist_df['apparent_temperature_mean (°C)'].rolling(window=5,min_periods=1).mean()\n",
    "  prec_sma = hist_df['precipitation_sum (mm)'].rolling(window=5,min_periods=1).mean()\n",
    "  data_month = histdata_dates['mm']\n",
    "  data_date = histdata_dates['dd']\n",
    "\n",
    "  # Form train and test matrices\n",
    "  X_train_summer = np.column_stack([maxtemp_sma[train_summer_filter],\n",
    "                                    mintemp_sma[train_summer_filter],\n",
    "                                    meantemp_sma[train_summer_filter],\n",
    "                                    apptempmax_sma[train_summer_filter],\n",
    "                                    apptempmin_sma[train_summer_filter],\n",
    "                                    apptempmean_sma[train_summer_filter],\n",
    "                                    prec_sma[train_summer_filter],\n",
    "                                    data_month[train_summer_filter],\n",
    "                                    data_date[train_summer_filter]\n",
    "                                  ])\n",
    "\n",
    "  X_train_winter = np.column_stack([maxtemp[train_winter_filter],\n",
    "                                    mintemp[train_winter_filter],\n",
    "                                    meantemp[train_winter_filter],\n",
    "                                    apptempmax[train_winter_filter],\n",
    "                                    apptempmin[train_winter_filter],\n",
    "                                    apptempmean[train_winter_filter],\n",
    "                                    prec[train_winter_filter],\n",
    "                                    data_month[train_winter_filter],\n",
    "                                    data_date[train_winter_filter]\n",
    "                                  ])\n",
    "\n",
    "  X_test_summer = np.column_stack([maxtemp[test_summer_filter],\n",
    "                                    mintemp[test_summer_filter],\n",
    "                                    meantemp[test_summer_filter],\n",
    "                                    apptempmax[test_summer_filter],\n",
    "                                    apptempmin[test_summer_filter],\n",
    "                                    apptempmean[test_summer_filter],\n",
    "                                    prec[test_summer_filter],\n",
    "                                    data_month[test_summer_filter],\n",
    "                                    data_date[test_summer_filter]\n",
    "                                  ])\n",
    "  X_test_winter = np.column_stack([maxtemp[test_winter_filter],\n",
    "                                    mintemp[test_winter_filter],\n",
    "                                    meantemp[test_winter_filter],\n",
    "                                    apptempmax[test_winter_filter],\n",
    "                                    apptempmin[test_winter_filter],\n",
    "                                    apptempmean[test_winter_filter],\n",
    "                                    prec[test_winter_filter],\n",
    "                                    data_month[test_winter_filter],\n",
    "                                    data_date[test_winter_filter]\n",
    "                                  ])\n",
    "\n",
    "  return X_train_summer, X_train_winter, X_test_summer, X_test_winter\n",
    "\n",
    "\n",
    "def train_svm(X_train):\n",
    "  # OCSVM hyperparameters\n",
    "  nu = 0.02\n",
    "  clf = OneClassSVM(gamma='scale', kernel=\"rbf\", nu=nu)\n",
    "  clf.fit(X_train)\n",
    "\n",
    "  y_pred_train = clf.predict(X_train)\n",
    "  n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "  print(\"Training Error:\", n_error_train/len(y_pred_train))\n",
    "\n",
    "  return clf\n",
    "\n",
    "\n",
    "def test_svm(clf, X_test, y_actual):\n",
    "  y_pred = clf.predict(X_test)\n",
    "  # Model Accuracy: how often is the classifier correct?\n",
    "  print(\"Accuracy:\",metrics.accuracy_score(y_actual, y_pred))\n",
    "  return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE4hcPEBHAGR"
   },
   "outputs": [],
   "source": [
    "# Test on 5 municipalities\n",
    "#Muncipality 1 - Bahdaiyatal\n",
    "mun1_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/historical_data/Badhaiyatal_open-meteo-28.15N81.45E146m.csv\"\n",
    "mun1_df = pd.read_csv(mun1_url)\n",
    "X1_train_summer, X1_train_winter, X1_test_summer, X1_test_winter = create_train_test_data(mun1_df)\n",
    "model1 = train_svm(X1_train_summer)\n",
    "\n",
    "#Muncipality 2 - Bardiya National Park\n",
    "mun2_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/historical_data/Bardiya%20National%20Park_open-meteo-28.44N81.41E313m.csv\"\n",
    "mun2_df = pd.read_csv(mun2_url)\n",
    "X2_train_summer, X2_train_winter, X2_test_summer, X2_test_winter = create_train_test_data(mun2_df)\n",
    "model2 = train_svm(X2_train_summer)\n",
    "\n",
    "#Muncipality 3 - Rapti Sonari\n",
    "mun3_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/historical_data/Rapti_Sonari_open-meteo-28.08N81.86E204m.csv\"\n",
    "mun3_df = pd.read_csv(mun3_url)\n",
    "X3_train_summer, X3_train_winter, X3_test_summer, X3_test_winter = create_train_test_data(mun3_df)\n",
    "model3 = train_svm(X3_train_summer)\n",
    "\n",
    "#Muncipality 4 - chingad\n",
    "mun4_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/historical_data/Chingad_open-meteo-28.65N81.69E1345m.csv\"\n",
    "mun4_df = pd.read_csv(mun4_url)\n",
    "X4_train_summer, X4_train_winter, X4_test_summer, X4_test_winter = create_train_test_data(mun4_df)\n",
    "model4 = train_svm(X4_train_summer)\n",
    "\n",
    "\n",
    "#Muncipality 5 - Gulariya\n",
    "mun5_url = \"https://raw.githubusercontent.com/spaudel/Heat-AI/refs/heads/main/historical_data/Gulariya_open-meteo-28.22N81.34E145m.csv\"\n",
    "mun5_df = pd.read_csv(mun5_url)\n",
    "X5_train_summer, X5_train_winter, X5_test_summer, X5_test_winter = create_train_test_data(mun5_df)\n",
    "model5 = train_svm(X5_train_summer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test with forecast data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZ65dKK3O0dh"
   },
   "outputs": [],
   "source": [
    "# Test Badhaiyataal with all 5 models\n",
    "print(\"Model 1: Trained on Badhaiyataal\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model1, X1_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model1, X1_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model1, X1_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 2: Trained on Bardiya NP\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model2, X1_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model2, X1_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model2, X1_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 3: Trained on Rapti Sonari\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model3, X1_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model3, X1_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model3, X1_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 4: Trained on Chingad\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model4, X1_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model4, X1_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model4, X1_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 5: Trained on Gulariya\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model5, X1_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model5, X1_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model5, X1_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8wfQKHmESuv"
   },
   "outputs": [],
   "source": [
    "print(\"Testing Bardiya National Park\")\n",
    "\n",
    "# Testing with badhaiyataal model\n",
    "print(\"\\n \\nModel 1: Trained on Badhaiyatal\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model1, X2_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model1, X2_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model1, X2_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "\n",
    "print(\"\\n \\nModel 2: Trained on Bardiya NP\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model2, X2_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model2, X2_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model2, X2_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 3: Trained on Rapti Sonari\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model3, X2_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model3, X2_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model3, X2_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 4: Trained on Chingad\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model4, X2_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model4, X2_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model4, X2_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 5: Trained on Gulariya\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model5, X2_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model5, X2_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model5, X2_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2YDZegXzx_I"
   },
   "outputs": [],
   "source": [
    "print(\"Testing Rapti Sonari\")\n",
    "\n",
    "# Testing with badhaiyataal model\n",
    "print(\"\\n \\nModel 1: Trained on Badhaiyatal\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model1, X3_train_winter, -1*np.ones(X3_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model1, X3_test_summer, 1*np.ones(X3_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model1, X3_test_winter, -1*np.ones(X3_test_winter.shape[0]))\n",
    "\n",
    "\n",
    "print(\"\\n \\nModel 2: Trained on Bardiya NP\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model2, X3_train_winter, -1*np.ones(X3_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model2, X3_test_summer, 1*np.ones(X3_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model2, X3_test_winter, -1*np.ones(X3_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 3: Trained on Rapti Sonari\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model3, X3_train_winter, -1*np.ones(X3_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model3, X3_test_summer, 1*np.ones(X3_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model3, X3_test_winter, -1*np.ones(X3_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 4: Trained on Chingad\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model4, X3_train_winter, -1*np.ones(X3_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model4, X3_test_summer, 1*np.ones(X3_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model4, X3_test_winter, -1*np.ones(X3_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 5: Trained on Gulariya\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model5, X3_train_winter, -1*np.ones(X3_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model5, X3_test_summer, 1*np.ones(X3_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model5, X3_test_winter, -1*np.ones(X3_test_winter.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9V5KUXaQdFr"
   },
   "outputs": [],
   "source": [
    "print(\"Testing Chingad\")\n",
    "\n",
    "# Testing with badhaiyataal model\n",
    "print(\"\\n \\nModel 1: Trained on Badhaiyatal\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model1, X4_train_winter, -1*np.ones(X4_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model1, X4_test_summer, 1*np.ones(X4_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model1, X4_test_winter, -1*np.ones(X4_test_winter.shape[0]))\n",
    "\n",
    "\n",
    "print(\"\\n \\nModel 2: Trained on Bardiya NP\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model2, X4_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model2, X4_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model2, X4_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 3: Trained on Rapti Sonari\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model3, X4_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model3, X4_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model3, X4_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 4: Trained on Chingad\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model4, X4_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model4, X4_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model4, X4_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 5: Trained on Gulariya\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model5, X4_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model5, X4_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model5, X4_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQHEDqIbQxoN"
   },
   "outputs": [],
   "source": [
    "print(\"Testing Gulariya\")\n",
    "\n",
    "# Testing with badhaiyataal model\n",
    "print(\"\\n \\nModel 1: Trained on Badhaiyatal\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model1, X5_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model1, X5_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model1, X5_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "\n",
    "print(\"\\n \\nModel 2: Trained on Bardiya NP\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model2, X5_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model2, X5_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model2, X5_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 3: Trained on Rapti Sonari\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model3, X5_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model3, X5_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model3, X5_test_winter, -1*np.ones(X2_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 4: Trained on Chingad\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model4, X5_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model4, X5_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model4, X5_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n",
    "\n",
    "print(\"\\n \\nModel 5: Trained on Gulariya\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(model5, X5_train_winter, -1*np.ones(X1_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(model5, X5_test_summer, 1*np.ones(X1_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(model5, X5_test_winter, -1*np.ones(X1_test_winter.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5wpIfucz-CT"
   },
   "outputs": [],
   "source": [
    "# Test on municipal data\n",
    "mun_id = '58001' #badhaiyataal\n",
    "from_date_time = '2024-10-24'\n",
    "to_date_time = '2024-11-05'\n",
    "\n",
    "# the below url gets daily forecast for the district for the given start and end date\n",
    "\n",
    "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/daily-municipality-location-forecast/?municipality=55003&from_date=2024-10-24&to_date=2024-11-05'\n",
    "badhaiyataal_forecast_output = requests.get(request_url)\n",
    "\n",
    "badhaiyataal_forecast_dict = badhaiyataal_forecast_output.json()\n",
    "from_date =\n",
    "badhaiyataal_forecast_dates\n",
    "print(len(badhaiyataal_forecast_dict))\n",
    "# Process the dictionary to get relevant detail\n",
    "# relevant keys: air_temperature, apparent temperature, precipitation\n",
    "# Decode the dictionary to create an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYy5LA3W3vf3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_inference_data(forecast_dict):\n",
    "  inference_array = np.zeros((len(forecast_dict),9)) # number of days, number of features\n",
    "  for x in range(len(forecast_dict)):\n",
    "    for key in forecast_dict[x].keys():\n",
    "      if key == \"max_air_temperature\":\n",
    "        inference_array[x,0] = forecast_dict[x][key]\n",
    "      if key == \"min_air_temperature\":\n",
    "        inference_array[x,1] = forecast_dict[x][key]\n",
    "      if key == \"mean_air_temperature\":\n",
    "        inference_array[x,2] = forecast_dict[x][key]\n",
    "      if key == \"max_calculated_heat_index\": #apparent temperature\n",
    "        inference_array[x,3] = forecast_dict[x][key]\n",
    "      if key == \"min_calculated_heat_index\": #apparent temperature\n",
    "        inference_array[x,4] = forecast_dict[x][key]\n",
    "      if key == \"mean_calculated_heat_index\": #apparent temperature\n",
    "        inference_array[x,5] = forecast_dict[x][key]\n",
    "      if key == \"total precipitation\": #\n",
    "        inference_array[x,6] = forecast_dict[x][key]\n",
    "      if key == \"date\":\n",
    "        forecast_date = extract_month(forecast_dict[x][key])\n",
    "        inference_array[x,7] = forecast_date[1]\n",
    "        inference_array[x,7] = forecast_date[2]\n",
    "  return inference_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baOpI_Wzs54R"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnEzmAzn30u1"
   },
   "outputs": [],
   "source": [
    "badhaiyataal_forecast = extract_inference_data(badhaiyataal_forecast_dict)\n",
    "y_pred = model1.predict(badhaiyataal_forecast)\n",
    "print(\"Predictions:\\n\",y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IedPL75GRYjF"
   },
   "outputs": [],
   "source": [
    "# Save models\n",
    "import pickle\n",
    "\n",
    "# save\n",
    "model_filename = \"models/\" + \"badhaiyataal\" + \"_trained_model.pkl\"\n",
    "# save\n",
    "with open(model_filename,'wb') as f:\n",
    "  pickle.dump(model1,f)\n",
    "with open('model_badhaiyataal.pkl', 'rb') as f:\n",
    "    saved_model = pickle.load(f)\n",
    "# Testing with saved model\n",
    "# Testing with badhaiyataal model\n",
    "print(\"\\n \\nModel 1: Trained on Badhaiyatal\")\n",
    "print(\"Testing historical winter\")\n",
    "test_svm(saved_model, X1_train_winter, -1*np.ones(X2_train_winter.shape[0]))\n",
    "print (\"Testing Summer post 2019\")\n",
    "test_svm(saved_model, X1_test_summer, 1*np.ones(X2_test_summer.shape[0]))\n",
    "print (\"Testing Winter post 2019\")\n",
    "test_svm(saved_model, X1_test_winter, -1*np.ones(X2_test_winter.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9mT-hRusnSg"
   },
   "outputs": [],
   "source": [
    "# Test on forecast municipal data\n",
    "mun_id = '58001' #badhaiyataal\n",
    "from_date_time = '2024-11-24'\n",
    "to_date_time = '2024-12-05'\n",
    "\n",
    "# the below url gets daily forecast for the district for the given start and end date\n",
    "\n",
    "request_url = 'https://heatai.dev.techcolab.org/api/v1/aiapis/daily-municipality-location-forecast/?municipality=55003&from_date=2024-10-24&to_date=2024-11-05'\n",
    "badhaiyataal_forecast_output = requests.get(request_url)\n",
    "\n",
    "badhaiyataal_forecast_dict = badhaiyataal_forecast_output.json()\n",
    "badhaiyataal_forecast = extract_inference_data(badhaiyataal_forecast_dict)\n",
    "\n",
    "with open('model_badhaiyataal.pkl', 'rb') as f:\n",
    "    saved_model = pickle.load(f)\n",
    "\n",
    "y_pred = saved_model.predict(badhaiyataal_forecast)\n",
    "print(\"Predictions:\\n\",y_pred)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNVbdRWCvvG7OktDZIpHH3q",
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
